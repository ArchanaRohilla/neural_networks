{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Model design with binning of \"APPLICATION_TYPE\" and \"CLASSIFICATION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "charity_df = pd.read_csv('Resources/charity_data.csv')\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the \"EIN\" & \"NAME\" columns\n",
    "charity_cleaned_df = charity_df.drop(columns=[\"EIN\",\"NAME\"], axis=1)\n",
    "charity_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = charity_cleaned_df.dtypes[charity_cleaned_df.dtypes == \"object\"].index.tolist()\n",
    "charity_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_cleaned_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the APPLICATION_TYPE value counts\n",
    "application_counts = charity_cleaned_df.APPLICATION_TYPE.value_counts()\n",
    "application_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26fb0f31308>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts\n",
    "application_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace for bucketing\n",
    "replace_applications = list(application_counts[application_counts < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in DataFrame\n",
    "for application in replace_applications:\n",
    "    charity_cleaned_df.APPLICATION_TYPE = charity_cleaned_df.APPLICATION_TYPE.replace(application,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "Other      120\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure bucketing was successful\n",
    "charity_cleaned_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C2300       32\n",
       "C7200       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C6000       15\n",
       "C1800       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1278       10\n",
       "C1238       10\n",
       "C1235        9\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the CLASSIFICATION value counts\n",
    "classification_counts = charity_cleaned_df.CLASSIFICATION.value_counts()\n",
    "classification_counts.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26fb1643d88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD5CAYAAADx05gdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5Rc5Xnn++/T1fd7q7t1F0hYwkaKjQ2KHB9ijyckAZyJlRzDWMwkwRwYchxYPknWORmYmcV4SFgTMmuOE9s4DjEkmPGKYIjH03aUMCY4tuMLqLENRsKCjiRQIwl1q2/q++2ZP/ZbrVJR1V3dXbuqq/X7rFX0rne/+93vLhX99HvZ7zZ3R0REJE5lxa6AiIisfgo2IiISOwUbERGJnYKNiIjETsFGRERip2AjIiKxK4+zcDO7HvgTIAF8wd3/MG1/FfBF4GrgLPBRdz8e9t0D3AbMAJ9w96dyLPMzwK3uXr/QObJpa2vzrVu3Lvm6RUQuRs8//3yvu7dn2hdbsDGzBPAg8AtAN3DQzDrc/XBKttuAfnffbmb7gAeAj5rZTmAfsAvYCDxtZpeHY7KWaWa7gea0qmQ8x3x137p1K52dnUu+dhGRi5GZvZZtX5zdaHuALnc/6u6TwH5gb1qevcCjYftJ4Fozs5C+390n3P0Y0BXKy1pmCG7/Bfi9HM8hIiIFEmew2QScSHnfHdIy5nH3aWAQaJ3n2PnKvAvocPdTOZ5DREQKJM4xm0yth/S1cbLlyZaeKTi6mW0EbgI+uMR6YGZ3AHcAXHLJJRkOERGRpYqzZdMNbEl5vxk4mS2PmZUDTUDfPMdmS38PsB3oMrPjQK2ZdS1wjgu4+0Puvtvdd7e3ZxzfEhGRJYoz2BwEdpjZNjOrJBrw70jL0wHcErZvBJ7xaGXQDmCfmVWZ2TZgB/BctjLd/W/cfb27b3X3rcCou29f4BwiIlIgsXWjufu0md0FPEU0TfkRdz9kZvcBne7eATwMPBZaIX1EwYOQ7wngMDAN3OnuMwCZylygKhnPISIihWP6I/+tdu/e7Zr6LCKyOGb2vLvvzrRPKwhI0czMOk90nuD7R88WuyoiErNYVxAQmc9ffvc4v/+1w5QZPPXbH2DHuoZiV0lEYqKWjRTFzKzzF985xva19ZSXlfGlZ18vdpVEJEYKNlIUL58aort/jI//s7fx8zvX8rUXT6HxQ5HVS8FGiiI5TnPN9jZ+dns7vcMTHOsdKXKtRCQuCjZSFM8e62Nray3rm6rZs60FgIPH33KvrYisEgo2UhQvnxripzY1AfC29nrqq8o5dHKoyLUSkbgo2EjBDY1P0d0/xhUbGgEwMy5fV89PTp8rcs1EJC4KNlJwr4Sg8o7156c6v319I0dOn9MkAZFVSsFGCu5oTzQRYPva+rm0t6+rZ3Bsip5zE8WqlojESMFGCu61vhESZcbG5pq5tEvb6gB4vW+0WNUSkRgp2EjBvd43xsbmaioS579+l6ypDfsUbERWIwUbKbjXz45w6Zq6C9I2t9RgpmAjslop2EjBvdY3yiWttRekVZUn2NBYrWAjskop2EhBDY5NMTA6NddtlmrLmlpOKNiIrEoKNlJQyWCSKdhcsqZWLRuRVUrBRgrq1OA4wAUz0ZK2rKnlzaEJJqZnCl0tEYlZrMHGzK43syNm1mVmd2fYX2Vmj4f9z5rZ1pR994T0I2Z23UJlmtnDZvaCmb1oZk+aWX1I/5iZ9ZjZj8Lr9jivWeZ3eigKNhuaqt+yb31jlHZmSPfaiKw2sQUbM0sADwI3ADuBm81sZ1q224B+d98OfAp4IBy7E9gH7AKuBz5nZokFyvwdd7/S3d8FvA7clXKex9393eH1hTiuV3JzenCMRJnRVl/1ln3rQwBKBiQRWT3ibNnsAbrc/ai7TwL7gb1pefYCj4btJ4FrzcxC+n53n3D3Y0BXKC9rme4+BBCOrwG07skKdHpwgrUNVSTK7C37ksEm2dUmIqtHnMFmE3Ai5X13SMuYx92ngUGgdZ5j5y3TzP4COA28A/hMSr6PpHSvbclUWTO7w8w6zayzp6cn54uUxXlzaJx1jW/tQoPzweZNBRuRVSfOYPPWP13f2trIlmex6dGG+63ARuBl4KMh+avA1tC99jTnW1IXFuL+kLvvdvfd7e3tmbJIHpweGp8bm0nXUFVObWVCLRuRVSjOYNMNpLYiNgMns+Uxs3KgCeib59gFy3T3GeBx4CPh/Vl3T444/zlw9ZKvSJbt9OD4XAsmnZmxvrGaNzVmI7LqxBlsDgI7zGybmVUSDfh3pOXpAG4J2zcCz3i0xnwHsC/MVtsG7ACey1amRbbD3JjNLwM/Ce83pJzvw0StHimC4YlphiemswYbiLrSNEFAZPUpj6tgd582s7uAp4AE8Ii7HzKz+4BOd+8AHgYeM7MuohbNvnDsITN7AjgMTAN3hhYLWcosAx41s0airrYXgI+HqnzCzD4cyukDPhbXNcv8zoQgsq7xrTPRktY3VvPsMT0eWmS1iS3YALj7AeBAWtq9KdvjwE1Zjr0fuD/HMmeBa7KUcw9wz2LrLvnXOzwJkHHac1J7YxU95yZwd6JGqoisBlpBQArm7HA0dNZalz3YtNVVMTkzy9D4dKGqJSIFoGAjBdM7Elo2DZVZ8yT39Q5rFQGR1UTBRgom2bJZUztPsAldbL16PLTIqqJgIwXTOzxBS20F5YnsX7u5YBPGd0RkdVCwkYI5OzxJ6zyTAyA12KhlI7KaKNhIwZwdnqStPnsXGsCaukrKTMFGZLVRsJGC6R2ZWLBlkygz1tRVqhtNZJVRsJGCOTs8SVvd/C0biLrS1LIRWV0UbKQgJqdnGRybmveGziQFG5HVR8FGCqIv3GOzUDcaQFt9pYKNyCqjYCMFkQwerQtMEIjyVNF7TmM2IquJgo0UxNnk6gE5BJu2+irGpmYYmdCSNSKrhYKNFERyRYDcxmy0ZI3IaqNgIwVxdiTZjbZwsFkTZqz1j07FWicRKRwFGymIs8OTVJWXUVeZWDBvSzLYjGjcRmS1ULCRgugdnqStviqnZ9QkF+rsU7ARWTViDTZmdr2ZHTGzLjO7O8P+KjN7POx/1sy2puy7J6QfMbPrFirTzB42sxfM7EUze9LM6hc6hxRO/+gkLXUVOeWda9mMKtiIrBaxBRszSwAPAjcAO4GbzWxnWrbbgH533w58CnggHLuT6BHRu4Drgc+ZWWKBMn/H3a9093cBrwN3zXcOKaz+0Ula5nm0QKrG6nISZaaWjcgqEmfLZg/Q5e5H3X0S2A/sTcuzF3g0bD8JXGtRP8teYL+7T7j7MaArlJe1THcfAgjH1wC+wDmkgAZGp2jOMdiYGS21lWrZiKwicQabTcCJlPfdIS1jHnefBgaB1nmOnbdMM/sL4DTwDuAzC5xDCmhgdJLmmty60QDW1FXQP6LZaCKrRZzBJlPrwXPMs9j0aMP9VmAj8DLw0UXUAzO7w8w6zayzp6cnwyGyVLOzzuDYFC21uQebltpK+tSyEVk14gw23cCWlPebgZPZ8phZOdAE9M1z7IJluvsM8DjwkQXOQdpxD7n7bnff3d7envNFysKGxqeYdXLuRoPoXhtNfRZZPeIMNgeBHWa2zcwqiQb8O9LydAC3hO0bgWfc3UP6vjCTbBuwA3guW5kW2Q5zYza/DPxkgXNIgSRvzsx1NlqUV2M2IqtJeVwFu/u0md0FPAUkgEfc/ZCZ3Qd0unsH8DDwmJl1EbU29oVjD5nZE8BhYBq4M7RYyFJmGfComTUSdZu9AHw8VCXjOaRwBkLQaK5ZRMumtpL+0SlmZ52yMs3nECl1sQUbAHc/ABxIS7s3ZXscuCnLsfcD9+dY5ixwTZZysp5DCmMgtGyaFzNmU1fJzKxzbnyapkUcJyIrk1YQkNglu8Nyvc8myhsFGE0SEFkdFGwkdnNjNosJNnVaskZkNVGwkdgNjE5SZtBQnXuvbXJ9NM1IE1kdFGwkdgOjUzTVVCxqoD/5mAF1o4msDgo2ErvFrIuWpMcMiKwuCjYSu4HRqUXPKKurTFCZKNMD1ERWCQUbid1SWjZmRktdhVo2IquEgo3ELlrxefH3ymh9NJHVQ8FGYjewhJYNaH00kdVEwUZiNTk9y8jkzKIeL5DUUqeWjchqoWAjsZpbF61uCS2b2krd1CmySijYSKwGxpKrByxlzKaCwbEpZma1SLdIqVOwkVglx1yWMmbTXFuJOwyNafqzSKlTsJFYJe+TaVrCmI1WERBZPRRsJFbJMZuWJYzZJKdLDyjYiJQ8BRuJ1fLGbJJL1qgbTaTUKdhIrPpHJ6ksL6OmIrHoY9WNJrJ6xBpszOx6MztiZl1mdneG/VVm9njY/6yZbU3Zd09IP2Jm1y1Uppl9KaS/ZGaPmFlFSP+gmQ2a2Y/C616kYAZGpmiuqcBs8Y92VjeayOoRW7AxswTwIHADsBO42cx2pmW7Deh39+3Ap4AHwrE7gX3ALuB64HNmlligzC8B7wDeCdQAt6ec59vu/u7wui//VyvZLGVdtKT6qnIqEqbFOEVWgThbNnuALnc/6u6TwH5gb1qevcCjYftJ4FqL/gTeC+x39wl3PwZ0hfKylunuBzwAngM2x3htkqOBsaWtiwbRYpzNtVqyRmQ1iDPYbAJOpLzvDmkZ87j7NDAItM5z7IJlhu6zXwf+LiX5fWb2gpn9rZntylRZM7vDzDrNrLOnpye3K5QFLXVdtKSW2gr61Y0mUvLiDDaZOunTbwXPlmex6ak+B3zL3b8d3v8AuNTdrwQ+A3wlU2Xd/SF33+3uu9vb2zNlkSXoX+KKz0kttZWajSayCsQZbLqBLSnvNwMns+Uxs3KgCeib59h5yzSz/wi0A7+bTHP3IXcfDtsHgAoza1vOhUlu3J2B0Umal9WyqVTLRmQViDPYHAR2mNk2M6skGvDvSMvTAdwStm8EngljLh3AvjBbbRuwg2gcJmuZZnY7cB1ws7vPJk9gZuvDOBBmtofoms/GcsVygdHJGaZmfEn32CS11FVogoDIKlAeV8HuPm1mdwFPAQngEXc/ZGb3AZ3u3gE8DDxmZl1ELZp94dhDZvYEcBiYBu509xmATGWGU34eeA34XogtXw4zz24EPm5m08AYsC8ENIlZskWy3G60gdFJ3H1J06dFZGWILdjAXLfVgbS0e1O2x4Gbshx7P3B/LmWG9IzX4u6fBT67qIpLXgyEFslyu9GmZ51zE9M0Vi89aIlIcWkFAYlNsmWzrNloYRWBAU0SEClpCjYSm2TLZlljNuFYLVkjUtoUbCQ2yWVmmpYRbJJdcJqRJlLaFGwkNnNjNjVL70ZLLsapVQRESpuCjcSmf3SK+qpyKsuX/jVLdqNp+rNIaVOwkdgMjE0u6QmdqRqrKygzrfwsUupyCjZm9tdm9ktmpuAkORsYnaKlbnnBpqwsWoyzT91oIiUt1+Dxp8C/Al41sz80s3fEWCdZJQZGJ5c1XpPUXFsxN/4jIqUpp2Dj7k+7+78GrgKOA183s++a2a3Jh5SJpBtY5iKcSWvUshEpeTl3i5lZK/AxooeS/RD4E6Lg8/VYaiYlbznPsknVrMU4RUpeTsvVmNmXiZ6C+Rjwy+5+Kux63Mw646qclK7ZWV/2s2ySWmoreOkNdaOJlLJc10b7QliTbI6ZVYUnae6OoV5S4s5NTDPrLHs2GkT32vRpMU6RkpZrN9ofZEj7Xj4rIqvLQB7WRUtqrq1kcnqWsamZZZclIsUxb8vGzNYTPXa5xszew/knZTYCtTHXTUrY+RWfl9+ySb2xs7Yy1oXKRSQmC/2fex3RpIDNwP+fkn4O+Hcx1UlWgfPPssnDmE3KkjWbmmuWXZ6IFN68wcbdHwUeNbOPuPtfF6hOsgoMjuWzZaPFOEVK3bxjNmb2a2Fzq5n9bvprocLN7HozO2JmXWZ2d4b9VWb2eNj/rJltTdl3T0g/YmbXLVSmmX0ppL9kZo8k7/+xyKdD/hfN7KoFPxVZtuTCmfkYs1kTViHQvTYipWuhCQJ14Wc90JDhlZWZJYAHgRuAncDNZrYzLdttQL+7bwc+BTwQjt1J9IjoXcD1wOfMLLFAmV8imp79TqCG6H4gQt4d4XUH0WoIErOB0LJprF7+GEuyK06rCIiUroW60f4s/PxPSyh7D9Dl7kcBzGw/sBc4nJJnL/DJsP0k8FmL5rbuBfa7+wRwzMy6QnlkKzN1araZPUc0zpQ8xxfd3YHvm1mzmW1IuVdIYjAwOkVjdTnlieUvp9dck5wgoJaNSKnKdSHOPzKzRjOrMLO/N7PelC62bDYBJ1Led4e0jHncfRoYBFrnOXbBMkP32a8Df7eIekieDYxO5mVyAEB5oozG6nI900akhOX6Z+cvuvsQ8C+IfllfDvx/CxyT6e47zzHPYtNTfQ74lrt/exH1wMzuMLNOM+vs6enJcIgsRv/o1LIeB52upa5Sz7QRKWG5Bpvkb40PAX/l7n05HNMNbEl5vxk4mS2PmZUDTUDfPMfOW6aZ/UegHUidvJBLPXD3h9x9t7vvbm9vz+HyZD4DY1M05allA1ofTaTU5RpsvmpmPwF2A39vZu3A+ALHHAR2mNk2M6skGvDvSMvTAdwStm8EngljKx3AvjBbbRvR4P5z85VpZrcT3Rd0s7vPpp3jN8KstJ8BBjVeE79oXbT8tWzW1FYo2IiUsJymCrn73Wb2ADDk7jNmNkI08D7fMdNmdhfwFJAAHnH3Q2Z2H9Dp7h3Aw8BjYQJAH1HwIOR7gmgywTRwp7vPAGQqM5zy88BrwPfC+llfdvf7gANELbIuYBS4NZdrluUZGJ2aG9jPh5baSl55czhv5YlIYS1mXuoVRPfbpB7zxfkOCDPEDqSl3ZuyPQ7clOXY+4H7cykzpGe8ltBSunO+ekp+zcw6Q+NTeZsgAMkxG7VsREpVro8YeAx4G/AjILkaorNAsJGL09DYFO75WT0gqaW2gtHJGSamZ6gqT+StXBEpjFxbNruBnaGVIDKv5A2d+Vg9ICn1xs51jQo2IqUm1wkCLwHr46yIrB7J7q6mfE4QCItxaskakdKUa8umDTgc7syfSCa6+4djqZWUtMHROFo2WkVApJTlGmw+GWclZHWZe7xAnmejgdZHEylVuU59/qaZXQrscPenzayWaOqxyFsMxNCyUTeaSGnLdW20f0O0UOafhaRNwFfiqpSUtoHRScoMGvKw4nNSshttQN1oIiUp1wkCdwLXAEMA7v4qsDauSklpGxiboqmmgrKyTMvSLU1VeYK6ygR9I+pGEylFuQabCXef+5My3NipadCSUf9ofm/oTGqurVTLRqRE5Rpsvmlm/w6oMbNfAP478NX4qiWlLHq8QP4mByS11Gl9NJFSlWuwuRvoAX4M/CbRcjH/Ia5KSWnL97poSS21lfRpNppIScp1NtqsmX0F+Iq762EvMq++kUl2rK3Pe7kttZW83jea93JFJH7ztmzCsvyfNLNe4CfAETPrMbN75ztOLm79o5NzU5XzqaW2Qk/rFClRC3Wj/TbRLLSfdvdWd18DvBe4xsx+J/baSckZn5phdHKGNfUxBJu6SobGp5memV04s4isKAsFm98gehjZsWSCux8Ffi3sE7lA8qbLNTHMRptbRWBM4zYipWahYFPh7r3piWHcJv8jwFLy5oJNHN1ooUx1pYmUnoWCzXz/V+v/eHmLOINNsrWkJWtESs9CweZKMxvK8DoHvHOhws3sejM7YmZdZnZ3hv1VZvZ42P+smW1N2XdPSD9iZtctVKaZ3RXS3MzaUtI/aGaDZvaj8NLkhhjFGWxawzhQ77CCjUipmXfqs7svebFNM0sADwK/AHQDB82sw90Pp2S7Deh39+1mtg94APiome0E9gG7gI3A02Z2eTgmW5nfAb4G/EOG6nzb3f/FUq9FchdnsGmrrwKgd3higZwistLkelPnUuwButz9aFjqZj+wNy3PXuDRsP0kcK2ZWUjf7+4TYXJCVygva5nu/kN3Px7j9UgO+kYmSZQZjdX5H9JbU1dJmcFZBRuRkhNnsNkEnEh53x3SMuZx92lgEGid59hcyszkfWb2gpn9rZntypTBzO4ws04z6+zp0X2rS3V2ZJKW2sq8LsKZlCgz1tRV0qNuNJGSE2ewyfTbJn3xzmx5Fps+nx8Al7r7lcBnyPJoBHd/yN13u/vu9vb2BYqUbPpHJllTF99Exda6KnWjiZSgOINNN7Al5f1m4GS2PGEl6Sagb55jcynzAu4+5O7DYfsAUJE6gUDyq28kntUDktoaKhVsREpQnMHmILDDzLaZWSXRgH9HWp4O4JawfSPwjLt7SN8XZqttA3YAz+VY5gXMbH0YB8LM9hBd89m8XKG8RV9MS9UktdWrZSNSivL3KMU07j5tZncBTxE9QvoRdz9kZvcBne7eATwMPGZmXUQtmn3h2ENm9gRwGJgG7nT3GYimOKeXGdI/AfwesB540cwOuPvtREHs42Y2DYwB+0JAkxjE3rKpr+KsxmxESk5swQbmuq0OpKXdm7I9DtyU5dj7gftzKTOkfxr4dIb0zwKfXWzdZfFmZp2B0clYlqpJaq2vZHRyhtHJaWorY/36ikgexdmNJheZwbEpZj2ee2yS5u61OafWjUgpUbCRvOkbicZSWmIMNu0h2PRo3EakpCjYSN70jUSrMbfWVcV2Dq0iIFKaFGwkb5Itmzi70ZLro2mSgEhpUbCRvEkukNkaw4PTks4vxqmWjUgpUbCRvOk5N4EZtMbYsqkqT9BYXa5gI1JiFGwkb3qGJ1hTW0l5It6vVVuDbuwUKTUKNpI3vecmaG+Ib3JAUlt9FT3nFGxESomCjeRNz/DE3GyxOK1rrObNIQUbkVKiYCN501Ogls36xipOD42jVYdESoeCjeSFu9M7XJhgs66xmsnpWQbHpmI/l4jkh4KN5MXwxDTjU7O0xTjtOWl9UzUAp4fGYz+XiOSHgo3kRXLAvjDdaCHYDCrYiJQKBRvJi+QNne311bGfa10INmc0SUCkZCjYSF4kWzZtDfF3o61tjFpP6kYTKR0KNpIXPeeiX/ztBZj6XFWeYE1dpYKNSAmJNdiY2fVmdsTMuszs7gz7q8zs8bD/WTPbmrLvnpB+xMyuW6hMM7srpLmZtaWkm5l9Oux70cyuiu+KL149wxMkyoyWGB+clmpdYzVvasxGpGTEFmzMLAE8CNwA7ARuNrOdadluA/rdfTvwKeCBcOxOokdE7wKuBz5nZokFyvwO8PPAa2nnuAHYEV53AH+az+uUSO+5SVrrKikrs4Kcb31jFW+eU7ARKRVxtmz2AF3uftTdJ4H9wN60PHuBR8P2k8C1ZmYhfb+7T7j7MaArlJe1THf/obsfz1CPvcAXPfJ9oNnMNuT1SoWeAt1jk7SusZrTg5ogIFIq4gw2m4ATKe+7Q1rGPO4+DQwCrfMcm0uZS6mHLFOhVg9IWtdYzdmRCaZmZgt2ThFZujiDTab+lPT1RbLlWWz6cuuBmd1hZp1m1tnT07NAkZKu59xEQSYHJK1vqsYdLcgpUiLiDDbdwJaU95uBk9nymFk50AT0zXNsLmUupR64+0Puvtvdd7e3ty9QpKSanpnlzLlxNjTFf49N0tyNnZqRJlIS4gw2B4EdZrbNzCqJBvw70vJ0ALeE7RuBZzxaXbED2Bdmq20jGtx/Lscy03UAvxFmpf0MMOjup/JxgRLpGZ5g1mF9U03BzrmhOQo2JwfGCnZOEVm68rgKdvdpM7sLeApIAI+4+yEzuw/odPcO4GHgMTPrImrR7AvHHjKzJ4DDwDRwp7vPQDTFOb3MkP4J4PeA9cCLZnbA3W8HDgAfIppkMArcGtc1X6xOhSnIhWzZbGqOAlt3v4KNSCmILdgAuPsBol/2qWn3pmyPAzdlOfZ+4P5cygzpnwY+nSHdgTsXW3fJXXKNsvUFDDYN1RU011bQ3T9asHOKyNJpBQFZtmK0bAA2t9SoZSNSIhRsZNlOD45RVV5GU01FQc+7ublWwUakRCjYyLKdGoxmokX34xZO1LIZ1RM7RUqAgo0s2+nB8YKO1yRtbqlhfGqWsyOTBT+3iCyOgo0sW9SyKdy056RNLbWAZqSJlAIFG1mW2VnnzaHitWwAzUgTKQEKNrIsvcMTTM96wWeiwflgc6JPLRuRlU7BRpblRGhVbAldWoXUUF1Ba10lx3tHCn5uEVkcBRtZltf7QrBZU/gxG4DL2us4pmAjsuIp2MiyJLuwNhehZQOwra2Oowo2Iiuego0sy+t9o6xtqKK6IlGU81/WXk/v8ARD41NFOb+I5EbBRpblRN8ol6wpTqsGopYNwLEetW5EVjIFG1mW7v4xthQx2FyWDDbqShNZ0RRsZMkmp2c5OVjcYHNJay1lhsZtRFY4BRtZspMDY7jDlpbizEQDqCpPsLmlln/qGS5aHURkYQo2smTnpz0Xr2UDcPm6el45fa6odRCR+SnYyJIdDa2J5LhJsVyxoZGjvSOMT80UtR4ikl2swcbMrjezI2bWZWZ3Z9hfZWaPh/3PmtnWlH33hPQjZnbdQmWa2bZQxquhzMqQ/jEz6zGzH4XX7XFe88Wkq2eYhupy2huqilqPd6xvZGbWefVNdaWJrFSxBRszSwAPAjcAO4GbzWxnWrbbgH533w58CnggHLsT2AfsAq4HPmdmiQXKfAD4lLvvAPpD2UmPu/u7w+sLMVzuRanrzDDb19YX/Dk26a7Y0ADAy6eGiloPEckuzpbNHqDL3Y+6+ySwH9iblmcv8GjYfhK41qLfXHuB/e4+4e7HgK5QXsYywzE/F8oglPkrMV6bAF1nRtjeXl/sanBpax01FQkOK9iIrFhxBptNwImU990hLWMed58GBoHWeY7Nlt4KDIQyMp3rI2b2opk9aWZbMlXWzO4ws04z6+zp6cn9Ki9Sg6NT9A5PsGNd8YNNosx4+/oGtWxEVrA4g02mvpX05/dmy5OvdICvAlvd/V3A05xvSV2Y2f0hd9/t7rvb29szZZEUXT3R7K/ta4sfbAB2bmzk8MkhZmf1iGiRlSjOYNMNpLYiNgMns+Uxs3KgCeib59hs6b1AcyjjgnO5+1l3nwjpfw5cvayrEiAar5PbJTYAAA9DSURBVAHY3t5Q5JpE3rOlmXMT03TpfhuRFSnOYHMQ2BFmiVUSDfh3pOXpAG4J2zcCz7i7h/R9YbbaNmAH8Fy2MsMx3whlEMr8nwBmtiHlfB8GXs7zdV6UjpweprqijE1FvKEz1e6tawDoPN5f5JqISCaxBZswfnIX8BTRL/gn3P2Qmd1nZh8O2R4GWs2sC/hd4O5w7CHgCeAw8HfAne4+k63MUNa/BX43lNUaygb4hJkdMrMXgE8AH4vrmi8mh04OcsWGRhJlxZ2JlrS1tZbWukqef03BRmQlKl84y9K5+wHgQFravSnb48BNWY69H7g/lzJD+lGi2Wrp6fcA9yy27pLd7Kxz6OQQv/qe9PkexWNmXH1pC8+/1lfsqohIBlpBQBbttb5Rhiem+alNjcWuygWuvrSF42dH6Tk3sXBmESkoBRtZtJfeGARg18amItfkQtdsbwPg269q6rrISqNgI4v2w9cHqCov4/J1K2MmWtLODY20N1TxjSMKNiIrjYKNLNrB4328e0szleUr6+tTVmZ88PJ2vnnkDNMzs8WujoikWFm/LWTFG56Y5tDJQfZsW1PsqmT0z9+xlqHxaX7w+kCxqyIiKRRsZFF+8Fo/sw4/vXVlBpv372ijqryMr76Qfv+wiBSTgo0syrdf7aEiEU0zXokaqiu4btd6Ol44ycS0nm8jslIo2MiifONID+/d1kpdVay3aC3L/3nVJgbHpnjm5TPFroqIBAo2krMTfaN0nRnmn79jbbGrMq/372hnQ1M1f/nd48WuiogECjaSs7/58SkAfv6KlR1sEmXG7e+/jGeP9XHwuFYUEFkJFGwkZ1/54Ru855JmLm2tK3ZVFnTzni2sqavkj59+hWidVhEpJgUbycmPuwf5yelzK2o9tPnUVpbziZ/bzne6ztKhmWkiRadgIzn5wj8epb6qnF8pkWAD8Ovv28qVm5u476uHOTkwVuzqiFzUFGxkQUd7hvnai6fY99NbaKyuKHZ1cpYoM/7rv7ySyelZbnu0k6HxqWJXSeSitXLnr8qK4O78wd+8TE1Fgt/8Z28rdnUWbfvaBj7zr97D7Y928i8//z3+/Dd2s2VN7aLL6R2e4JXT53j1zDCnBsc5OzzBufFpAMrKoLm2kvb6KrasqWXnhka2r61fccv5iBSTgo3M6/GDJ3jmJ2f4D790Be0NVcWuzpJ88O1r+ctb9/Dx//Y8v/ipb/FvPnAZv/beS1jbWJ0xf//IJC90D/DCiUFe6B7gxe4Beocn5/ZXJIzWuioaa8oxjBl3+kcmOTtyYZ53bmrimu1t/B9va+OqS5upKk/Efq0iK5XFOVPHzK4H/gRIAF9w9z9M218FfBG4GjgLfNTdj4d99wC3ATPAJ9z9qfnKDI+P3g+sAX4A/Lq7T853jmx2797tnZ2dy77+UvfMT97kNx97np+5rJW/vHXPinkq51K9MTDGfV89xFOH3gTg8nX1bG2to766nImpWXrOTXD87AhnwvNwzGB7ez3v2tzMzo2NvH1dA5evq6e9oQqzt34Wk9OzvN43yuFTQxw6OcizR/t4sXuAWYeaigTvvWwN79/Rzgd2tLF9bX3GMmRpBkYnOXRyiJfeGKTrzDA9wxP0jUwyM+skyozqigTrG6vZ0FTNjnUNXLGhge1r6/UHQJ6Z2fPuvjvjvriCjZklgFeAXwC6gYPAze5+OCXPbwHvcvf/28z2Ab/q7h81s53AXxE9eXMj8DRweTgsY5lm9gTwZXffb2afB15w9z/Ndo756n6xB5vRyWk+/82jfPaZV9m1sYn/dvt7aaopnbGahfxTzzB/99JpOo/38cbAGCMTM1RVlLGmtpKtbXVsX1vPuzY38c5NTTQsc4xqaHyKZ4/28Z2uXr71ag9He0YAWN9Yzft3tPGzO6KWT6m2GgvN3XlzaIKXQ0B/6Y0hXjo5SHf/+QkgaxuqWNtYRWtdFRUJY9ajBWTfHBrn1OA4k9PRiuDlZcaOdQ28c1MjP7WpiV0bm9i5oZGaSgWgpSpWsHkf8El3vy68vwfA3f9zSp6nQp7vmVk5cBpoB+5OzZvMFw57S5nAHwI9wHp3n049d7Zz+DwXfjEFG3dncGyKM+ei/4GfO9bHgR+fon90il9590b+4FffSf0KXpqm1HT3j/KPr/by7Vd7+ceuXgbHokkLaxuq5lpPm1pq2NhUw4bmapprK6mvKqe+qrzkW5a5mJie4dz4NMPj0/SNTnJyYIyTA2O80T/Gq2eGefnUEP2j5yd6bGurY9fGKFj81MYmdm1spKWuMmv5M7POsd4RXj41FFqgUWuoL3SBlhlsX1vPro1NXNpay8bmGjY319DWUEVDdTmN1RXUVibUKs1ivmAT52+RTcCJlPfdwHuz5QlBYhBoDenfTzs2Oec2U5mtwIC7T2fIn+0cvUu+siy++UoPv/+1w3M3Efrcf+Z+4O4p28l9fn47LQQumJ/04zLty1BGSBubnGF69vxJayoSXHvFWm69ZitXX7oyV3YuZZtbatm35xL27bmEmVnnpTcGOXi8j8Onhjh8cojvdp1lMsuzeGorE1QkyigvMxJlFv1MGOVlZeT6uy/XX5G5/DJNfofco+1ZP//dTKY5MOtR2mz4HyLaPn/srDs4TEzPZr32hupytrXV8Ys713PFhgau2NDIzo2Ni255JsqM7Wvr2b62nl++cuPcdZwaHOelNwZ5KQSf7/3TWf7HD9/IWkZ1eRmJMqMicf5necIoM8v8GWf5OLN9ypk+/0KFt4/+9BZuf/9leS83zmCT6bNJb01ky5MtPdP0nvny51oPzOwO4A6ASy65JMMhC6uvKuftyadX2vkfyS9OsiJmqdsX7sMg+XW1C8pIbp/fZ6kH5ZI/7ZwANZUJ2uqraKuvZMfaaEyiPKFZVIWQKDOu3NLMlVua59JmZ53ekQlODoxzamCMofEpzo1PR3/tT0wzM+tMz85GP2ecmVlnatZzWiUh5z6MHDI6jmHhe2iU2fnvuoXvsBkh3SgrA9LSou3z38+q8gQN1eVzr6aaCjY217CxuSbWKfdmNneeX9y1fi59YnqG04PjvNE/xtmRyfDvMMXQ+BQTU7NMzzpTM9G/xdSMMzM7y0yGzy7bv03WjzlTGbn/6y1bW308XbpxBptuYEvK+81A+q3cyTzdoYurCehb4NhM6b1As5mVh9ZNav5s57iAuz8EPARRN9qirjS4+tKWFbv0vpSGsjJjbUM1axuqeXdKEJLCqypPcGlrXUksz1QK4vwT9iCww8y2mVklsA/oSMvTAdwStm8EngljKR3APjOrCrPMdgDPZSszHPONUAahzP+5wDlERKRAYmvZhPGRu4CniKYpP+Luh8zsPqDT3TuAh4HHzKyLqLWxLxx7KMwuOwxMA3e6+wxApjLDKf8tsN/M/gD4YSibbOcQEZHCifU+m1J1Mc1GExHJl/lmo2kkWEREYqdgIyIisVOwERGR2CnYiIhI7BRsREQkdpqNloGZ9QCvpSS1EcPyNjFSfeNTSnUF1Tduqu+FLnX39kw7FGxyYGad2abzrUSqb3xKqa6g+sZN9c2dutFERCR2CjYiIhI7BZvcPFTsCiyS6hufUqorqL5xU31zpDEbERGJnVo2IiISu4sy2JjZTWZ2yMxmzWx32r57zKzLzI6Y2XUp6deHtC4zuzslfZuZPWtmr5rZ4+HRB4THIzwe8j9rZlvzVPdPmtkbZvaj8PpQvuteKNnqVQxmdtzMfhw+086QtsbMvh4+n6+bWUtINzP7dKj3i2Z2VUo5t4T8r5rZLdnOt4T6PWJmZ8zspZS0vNXPzK4O198Vjl3WgyGz1HdFfnfNbIuZfcPMXg6/F/6fkL4iP9956rsiP9857n7RvYArgLcD/wDsTknfCbwAVAHbgH8iepRBImxfBlSGPDvDMU8A+8L254GPh+3fAj4ftvcBj+ep7p8E/t8M6Xmre4H+DbLWq0jfieNAW1raHwF3h+27gQfC9oeAvyV6OOXPAM+G9DXA0fCzJWy35Kl+HwCuAl6Ko35Ez4t6Xzjmb4EbYqjvivzuAhuAq8J2A/BKqNOK/Hznqe+K/HyTr4uyZePuL7v7kQy79gL73X3C3Y8BXcCe8Opy96PuPgnsB/aGv05+DngyHP8o8CspZT0atp8Erl3uX4sLyGfdCyFjvQp4/lyk/hum/9t+0SPfJ3pK7AbgOuDr7t7n7v3A14Hr81ERd/8Wb33CbF7qF/Y1uvv3PPrt8kWW+V3IUt9sivrddfdT7v6DsH0OeBnYxAr9fOepbzYr4nfDRRls5rEJOJHyvjukZUtvBQY8ehR1avoFZYX9gyF/PtwVmu+PJJv2ea57IWSrV7E48L/M7HkzuyOkrXP3UxD9Dw6sDemL/azjkq/6bQrb6elxWNHfXYu6u98DPEsJfL5p9YUV/Pmu2mBjZk+b2UsZXvP99Zyp5eFLSJ+vrAUtUPc/Bd4GvBs4BfzXGOpeCMU+f7pr3P0q4AbgTjP7wDx5V+pnmrRSvwsr+rtrZvXAXwO/7e5D82VdZL0KVd8V/fnG9ljoYnP3n1/CYd3AlpT3m4GTYTtTei9RE7o8/BWQmj9ZVreZlQNN5NitkGvdzezPga/FUPdCmK++BefuJ8PPM2b2P4i6GN40sw3ufip0hZwJ2bPVvRv4YFr6P8RY7XzVrztsp+fPK3d/M7m90r67ZlZB9Iv7S+7+5ZC8Yj/fTPVdyZ8voYIX7Yu3ThDYxYUDaUeJBtHKw/Y2zg+k7QrH/HcuHEj7rbB9JxdOEHgiT3XekLL9O0R9sXmte4E++6z1KsL3oA5oSNn+LtFYy3/hwgHiPwrbv8SFA8TPhfQ1wDGiweGWsL0mj/XcyoUD7nmrH3Aw5E0OYH8ohvquyO9uuOYvAn+clr4iP9956rsiP9+5OuXrf4RSegG/ShTtJ4A3gadS9v17ohkaR0iZMUI0A+WVsO/fp6RfRjTTpCv8A1WF9OrwvivsvyxPdX8M+DHwItCR9gXLS90L+O+QsV5F+D5cFv5HewE4lKwLUd/13wOvhp/JXxwGPBjq/WMu/IPl/wqfZxdwax7r+FdEXSNT4bt7Wz7rB+wGXgrHfJZww3ee67siv7vAzxJ1E70I/Ci8PrRSP9956rsiP9/kSysIiIhI7FbtBAEREVk5FGxERCR2CjYiIhI7BRsREYmdgo2IiMROwUZERGKnYCMiIrFTsBERkdj9b4znsg9uEJbbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts\n",
    "classification_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace for bucketing\n",
    "replace_classifications = list(classification_counts[classification_counts < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in DataFrame\n",
    "for classification in replace_classifications:\n",
    "    charity_cleaned_df.CLASSIFICATION = charity_cleaned_df.CLASSIFICATION.replace(classification,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure bucketing was successful\n",
    "charity_cleaned_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   38   39   40   41  \\\n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "\n",
       "    42   43   44   45   46   47  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(charity_cleaned_df[charity_cat]))\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>APPLICATION_TYPE_T9</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T9  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                  0.0  ...                0.0                     0.0   \n",
       "1                  0.0  ...                1.0                     0.0   \n",
       "2                  0.0  ...                0.0                     0.0   \n",
       "3                  0.0  ...                0.0                     1.0   \n",
       "4                  0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(charity_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "charity_cleaned_df = charity_cleaned_df.merge(encode_df,left_index=True, right_index=True)\n",
    "charity_cleaned_df = charity_cleaned_df.drop(charity_cat,1)\n",
    "charity_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our target and features arrays\n",
    "y = charity_cleaned_df[\"IS_SUCCESSFUL\"].values\n",
    "X = charity_cleaned_df.drop([\"IS_SUCCESSFUL\"],1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 5.0000000e+03, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 1.0859000e+05, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.0000000e+03, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [1.0000000e+00, 5.0000000e+03, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.0000000e+03, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 3.6500179e+07, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34299"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34299"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25724"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25724"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8575"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8575"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 607\n",
      "Trainable params: 607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "hidden_nodes_layer2 = 8\n",
    "\n",
    "nn_1 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_1.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_1.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 0.5914 - accuracy: 0.7133\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5633 - accuracy: 0.7276\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5585 - accuracy: 0.7298\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5561 - accuracy: 0.7305\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5545 - accuracy: 0.7313\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5529 - accuracy: 0.7329\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5520 - accuracy: 0.7324\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5507 - accuracy: 0.7336\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5494 - accuracy: 0.7335\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5490 - accuracy: 0.7338\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5482 - accuracy: 0.7342\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5483 - accuracy: 0.7335\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5463 - accuracy: 0.7338\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5460 - accuracy: 0.7348\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5458 - accuracy: 0.7353\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5454 - accuracy: 0.7341\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5450 - accuracy: 0.7350\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5450 - accuracy: 0.7346\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5448 - accuracy: 0.7341\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5443 - accuracy: 0.7352\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5439 - accuracy: 0.7352\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5445 - accuracy: 0.7346\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5440 - accuracy: 0.7344\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5437 - accuracy: 0.7359\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5437 - accuracy: 0.7359\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5438 - accuracy: 0.7352\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5434 - accuracy: 0.7348\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 0.5433 - accuracy: 0.7356\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.5431 - accuracy: 0.7359\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5431 - accuracy: 0.7346\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.5430 - accuracy: 0.7353\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5431 - accuracy: 0.7352\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5428 - accuracy: 0.7353\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5427 - accuracy: 0.7361\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5428 - accuracy: 0.7358\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5424 - accuracy: 0.7357\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5422 - accuracy: 0.7357\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5424 - accuracy: 0.7347\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5422 - accuracy: 0.7357\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5424 - accuracy: 0.7362\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5424 - accuracy: 0.7357\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5420 - accuracy: 0.7362\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5418 - accuracy: 0.7363\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5420 - accuracy: 0.7365\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5417 - accuracy: 0.7371\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5417 - accuracy: 0.7368\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5416 - accuracy: 0.7369\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5413 - accuracy: 0.7372\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5418 - accuracy: 0.7377\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5415 - accuracy: 0.7355\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_1.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 1s - loss: 0.5532 - accuracy: 0.7272\n",
      "Loss: 0.5532226133277048, Accuracy: 0.7272303104400635\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_1.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 659\n",
      "Trainable params: 659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "hidden_nodes_layer2 = 8\n",
    "hidden_nodes_layer3 = 6\n",
    "\n",
    "nn_2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.5890 - accuracy: 0.7091\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5572 - accuracy: 0.7271\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5530 - accuracy: 0.7287\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5511 - accuracy: 0.7296\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5499 - accuracy: 0.7308\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.5486 - accuracy: 0.7316\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5486 - accuracy: 0.7321\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5474 - accuracy: 0.7320\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5471 - accuracy: 0.7326\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5467 - accuracy: 0.7331\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5464 - accuracy: 0.7327\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5458 - accuracy: 0.7328\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5454 - accuracy: 0.7328\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5453 - accuracy: 0.7333\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5450 - accuracy: 0.7334\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5447 - accuracy: 0.7329\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5446 - accuracy: 0.7336\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5446 - accuracy: 0.7335\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5441 - accuracy: 0.7333\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5442 - accuracy: 0.7330\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5439 - accuracy: 0.7341\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5436 - accuracy: 0.7344s - loss: 0.5414 - ac\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5436 - accuracy: 0.7338\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5433 - accuracy: 0.7349\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5432 - accuracy: 0.7347\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5433 - accuracy: 0.7339\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5432 - accuracy: 0.7340\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5432 - accuracy: 0.7348\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5433 - accuracy: 0.7342\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5430 - accuracy: 0.7349\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5427 - accuracy: 0.7349\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5428 - accuracy: 0.7350\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5427 - accuracy: 0.7348\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5426 - accuracy: 0.7357\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5424 - accuracy: 0.7347\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5426 - accuracy: 0.7353\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5419 - accuracy: 0.7355s - loss: 0.5\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5423 - accuracy: 0.7350\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5419 - accuracy: 0.7352\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5421 - accuracy: 0.7354\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5418 - accuracy: 0.7354\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5418 - accuracy: 0.7363\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5421 - accuracy: 0.7358\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5416 - accuracy: 0.7358\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5420 - accuracy: 0.7356\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5417 - accuracy: 0.7367\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.5416 - accuracy: 0.7360 - loss: 0.5403 - accu - ETA: 0s - loss: - ETA: 0s\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5414 - accuracy: 0.7368s - loss: 0.5412 \n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5413 - accuracy: 0.7359\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5415 - accuracy: 0.7372\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_2.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5505 - accuracy: 0.7276\n",
      "Loss: 0.5504939567521432, Accuracy: 0.727580189704895\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 679\n",
      "Trainable params: 679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "hidden_nodes_layer2 = 8\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.6103 - accuracy: 0.6862\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5666 - accuracy: 0.7190\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5595 - accuracy: 0.7261\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5554 - accuracy: 0.7292\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5526 - accuracy: 0.7291\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5515 - accuracy: 0.7299\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5499 - accuracy: 0.7313\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5490 - accuracy: 0.7312\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5484 - accuracy: 0.7315\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5477 - accuracy: 0.7327\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5473 - accuracy: 0.7325\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5469 - accuracy: 0.7325\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5463 - accuracy: 0.7343\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5456 - accuracy: 0.7345\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5453 - accuracy: 0.7348\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5452 - accuracy: 0.7351\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5453 - accuracy: 0.7347\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5446 - accuracy: 0.7353\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5449 - accuracy: 0.7362\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5448 - accuracy: 0.7341\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5444 - accuracy: 0.7364s - loss: 0.5424 - accuracy\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5445 - accuracy: 0.7358\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5439 - accuracy: 0.7373\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5442 - accuracy: 0.7362\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5437 - accuracy: 0.7372\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5437 - accuracy: 0.7358\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5437 - accuracy: 0.7378\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5439 - accuracy: 0.7367\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5432 - accuracy: 0.7374\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5431 - accuracy: 0.7350\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.5435 - accuracy: 0.7367\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5431 - accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5428 - accuracy: 0.7361s - loss: 0.543\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5433 - accuracy: 0.7369\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5429 - accuracy: 0.7367\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5428 - accuracy: 0.7369\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5424 - accuracy: 0.7371\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5423 - accuracy: 0.7379\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5424 - accuracy: 0.7372\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5424 - accuracy: 0.7368\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5424 - accuracy: 0.7374\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5419 - accuracy: 0.7362\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5418 - accuracy: 0.7371\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5419 - accuracy: 0.7373s - loss: 0.5\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5419 - accuracy: 0.7373\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5415 - accuracy: 0.7372\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5418 - accuracy: 0.7377\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5413 - accuracy: 0.7372\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5413 - accuracy: 0.7369\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5410 - accuracy: 0.7383 - loss: 0.5436 - accuracy: 0.73 - ETA: 1s - l\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_3.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5512 - accuracy: 0.7258\n",
      "Loss: 0.5511872530400579, Accuracy: 0.7258309125900269\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5413 - accuracy: 0.7366\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5415 - accuracy: 0.7376\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5408 - accuracy: 0.7376\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5415 - accuracy: 0.7374\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5411 - accuracy: 0.7376\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5413 - accuracy: 0.7372\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5410 - accuracy: 0.7379\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5406 - accuracy: 0.7371s - loss: 0.5428 - accuracy: 0.\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5411 - accuracy: 0.7372\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5415 - accuracy: 0.7371\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5405 - accuracy: 0.7374\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5405 - accuracy: 0.7368\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5406 - accuracy: 0.7379\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5408 - accuracy: 0.7372\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5406 - accuracy: 0.7378\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5407 - accuracy: 0.7376\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5407 - accuracy: 0.7367\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5405 - accuracy: 0.7375\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5405 - accuracy: 0.7372\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5404 - accuracy: 0.7385\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5402 - accuracy: 0.7385\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5407 - accuracy: 0.7377\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5405 - accuracy: 0.7374\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5405 - accuracy: 0.7372\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.73 - 1s 57us/sample - loss: 0.5401 - accuracy: 0.7383\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5400 - accuracy: 0.7376\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5403 - accuracy: 0.7380\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5394 - accuracy: 0.7374\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5398 - accuracy: 0.7371\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5400 - accuracy: 0.7380\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5397 - accuracy: 0.7385\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5398 - accuracy: 0.7376\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.5395 - accuracy: 0.7389\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5399 - accuracy: 0.7376\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5395 - accuracy: 0.7376\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5398 - accuracy: 0.7382\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5392 - accuracy: 0.7381\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5394 - accuracy: 0.7383\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5389 - accuracy: 0.7379\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5395 - accuracy: 0.7383\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.5395 - accuracy: 0.7375\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5394 - accuracy: 0.7384\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5400 - accuracy: 0.7388\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5398 - accuracy: 0.7374\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5393 - accuracy: 0.7378\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5394 - accuracy: 0.7381\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5396 - accuracy: 0.7383\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5394 - accuracy: 0.7388\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5388 - accuracy: 0.7383\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5393 - accuracy: 0.7387\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5390 - accuracy: 0.7386\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5394 - accuracy: 0.7384\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5393 - accuracy: 0.7379\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5395 - accuracy: 0.7371\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5391 - accuracy: 0.7386\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5391 - accuracy: 0.7379\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5390 - accuracy: 0.7386\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.73 - 1s 39us/sample - loss: 0.5390 - accuracy: 0.7387\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5391 - accuracy: 0.7385\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5392 - accuracy: 0.7379\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5392 - accuracy: 0.7379\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5393 - accuracy: 0.7388s - loss: 0.5374 - accura\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5388 - accuracy: 0.7377\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5387 - accuracy: 0.7376\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.5392 - accuracy: 0.7379\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5390 - accuracy: 0.7386\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5391 - accuracy: 0.7388\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5390 - accuracy: 0.7380\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5392 - accuracy: 0.7390\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5389 - accuracy: 0.7380\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5387 - accuracy: 0.7386\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5390 - accuracy: 0.7381\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5386 - accuracy: 0.7389\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.5387 - accuracy: 0.7375\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5389 - accuracy: 0.7388\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5385 - accuracy: 0.7387\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5388 - accuracy: 0.7387\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5385 - accuracy: 0.7388\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5387 - accuracy: 0.7376s - loss: 0.5341 - \n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5385 - accuracy: 0.7385\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5385 - accuracy: 0.7383\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5385 - accuracy: 0.7384\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5380 - accuracy: 0.7396\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5382 - accuracy: 0.7385\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5384 - accuracy: 0.7388\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5383 - accuracy: 0.7390\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5386 - accuracy: 0.7388\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5383 - accuracy: 0.7386\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5383 - accuracy: 0.7381\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5385 - accuracy: 0.7387\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5379 - accuracy: 0.7384\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5384 - accuracy: 0.7396\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5378 - accuracy: 0.7388\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5376 - accuracy: 0.7388\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5378 - accuracy: 0.7385\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5382 - accuracy: 0.7389\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5378 - accuracy: 0.7390\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.5380 - accuracy: 0.7391\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5377 - accuracy: 0.7397\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5378 - accuracy: 0.7383\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_3.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5521 - accuracy: 0.7254\n",
      "Loss: 0.5520622838064811, Accuracy: 0.7253644466400146\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Model design with binning of \"CLASSIFICATION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "charity_df = pd.read_csv('Resources/charity_data.csv')\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the \"EIN\" & \"NAME\" columns\n",
    "charity_cleaned_2 = charity_df.drop(columns=[\"EIN\",\"NAME\"], axis=1)\n",
    "charity_cleaned_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat_1 = charity_cleaned_2.dtypes[charity_cleaned_2.dtypes == \"object\"].index.tolist()\n",
    "charity_cat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_cleaned_2[charity_cat_1].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C2300       32\n",
       "C7200       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C6000       15\n",
       "C1800       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1278       10\n",
       "C1238       10\n",
       "C1235        9\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the CLASSIFICATION value counts\n",
    "classification_counts_1 = charity_cleaned_2.CLASSIFICATION.value_counts()\n",
    "classification_counts_1.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace for bucketing\n",
    "replace_classifications_1 = list(classification_counts_1[classification_counts_1 < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in DataFrame\n",
    "for classification in replace_classifications_1:\n",
    "    charity_cleaned_2.CLASSIFICATION = charity_cleaned_2.CLASSIFICATION.replace(classification,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure bucketing was successful\n",
    "charity_cleaned_2.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder instance\n",
    "enc2 = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   45   46   47   48  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "\n",
       "    49   50   51   52   53   54  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_2 = pd.DataFrame(enc2.fit_transform(charity_cleaned_2[charity_cat_1]))\n",
    "encode_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>APPLICATION_TYPE_T25</th>\n",
       "      <th>APPLICATION_TYPE_T29</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
       "0                   0.0                  0.0                   0.0   \n",
       "1                   0.0                  0.0                   0.0   \n",
       "2                   0.0                  0.0                   0.0   \n",
       "3                   0.0                  0.0                   0.0   \n",
       "4                   0.0                  0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T29  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                   0.0  ...                0.0                     0.0   \n",
       "1                   0.0  ...                1.0                     0.0   \n",
       "2                   0.0  ...                0.0                     0.0   \n",
       "3                   0.0  ...                0.0                     1.0   \n",
       "4                   0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the encoded variable names to the DataFrame\n",
    "encode_2.columns = enc2.get_feature_names(charity_cat_1)\n",
    "encode_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "0       1     5000              1                   1.0                   0.0   \n",
       "1       1   108590              1                   0.0                   0.0   \n",
       "2       1     5000              0                   0.0                   0.0   \n",
       "3       1     6692              1                   0.0                   0.0   \n",
       "4       1   142590              1                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  ...  INCOME_AMT_1-9999  \\\n",
       "0                   0.0                   0.0  ...                0.0   \n",
       "1                   0.0                   0.0  ...                1.0   \n",
       "2                   0.0                   0.0  ...                0.0   \n",
       "3                   0.0                   0.0  ...                0.0   \n",
       "4                   0.0                   0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "charity_cleaned_3 = charity_cleaned_2.merge(encode_2,left_index=True, right_index=True)\n",
    "charity_cleaned_3 = charity_cleaned_3.drop(charity_cat_1,1)\n",
    "charity_cleaned_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our target and features arrays\n",
    "y = charity_cleaned_3[\"IS_SUCCESSFUL\"].values\n",
    "X = charity_cleaned_3.drop([\"IS_SUCCESSFUL\"],1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 12)                696       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 865\n",
      "Trainable params: 865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 12\n",
    "# hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# # Third hidden layer\n",
    "# nn_4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_4.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_4.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5903 - accuracy: 0.7109\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5587 - accuracy: 0.7283\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5540 - accuracy: 0.7302\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5517 - accuracy: 0.7318\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5502 - accuracy: 0.7326\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5490 - accuracy: 0.7336\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5482 - accuracy: 0.7331\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5478 - accuracy: 0.7344\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5469 - accuracy: 0.7340\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5466 - accuracy: 0.7333\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5459 - accuracy: 0.7350\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5457 - accuracy: 0.7352\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5453 - accuracy: 0.7344\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5450 - accuracy: 0.7350\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5447 - accuracy: 0.7348\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5441 - accuracy: 0.7344\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5439 - accuracy: 0.7347\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5440 - accuracy: 0.7349\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5436 - accuracy: 0.7346\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5433 - accuracy: 0.7343\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5425 - accuracy: 0.7362\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5426 - accuracy: 0.7361\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5425 - accuracy: 0.7349\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5422 - accuracy: 0.7364\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5423 - accuracy: 0.7349\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5420 - accuracy: 0.7360\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 36us/sample - loss: 0.5419 - accuracy: 0.7357\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5414 - accuracy: 0.7357\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5415 - accuracy: 0.7355\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5418 - accuracy: 0.7364\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5410 - accuracy: 0.7364\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5413 - accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5408 - accuracy: 0.7372\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5406 - accuracy: 0.7372\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5406 - accuracy: 0.7367\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5408 - accuracy: 0.7366\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5399 - accuracy: 0.7367\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5405 - accuracy: 0.7362\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5402 - accuracy: 0.7364\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5403 - accuracy: 0.7368\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5403 - accuracy: 0.7365\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5400 - accuracy: 0.7364\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.5397 - accuracy: 0.7371\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5400 - accuracy: 0.7373\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5400 - accuracy: 0.7361\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5398 - accuracy: 0.7367\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5397 - accuracy: 0.7370\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5399 - accuracy: 0.7375\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5398 - accuracy: 0.7371\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5395 - accuracy: 0.7365\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_4.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5508 - accuracy: 0.7266\n",
      "Loss: 0.5507525352277839, Accuracy: 0.7266472578048706\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 12)                696       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 923\n",
      "Trainable params: 923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 10\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_5.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_5.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/75\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.6028 - accuracy: 0.6948\n",
      "Epoch 2/75\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5604 - accuracy: 0.7257\n",
      "Epoch 3/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5544 - accuracy: 0.7284\n",
      "Epoch 4/75\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5512 - accuracy: 0.7316\n",
      "Epoch 5/75\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5493 - accuracy: 0.7322\n",
      "Epoch 6/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5482 - accuracy: 0.7311\n",
      "Epoch 7/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5476 - accuracy: 0.7329\n",
      "Epoch 8/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5465 - accuracy: 0.7330\n",
      "Epoch 9/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5466 - accuracy: 0.7333\n",
      "Epoch 10/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5461 - accuracy: 0.7335\n",
      "Epoch 11/75\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5453 - accuracy: 0.7337\n",
      "Epoch 12/75\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 0.5451 - accuracy: 0.7345\n",
      "Epoch 13/75\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5443 - accuracy: 0.7344\n",
      "Epoch 14/75\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5445 - accuracy: 0.7351\n",
      "Epoch 15/75\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.5440 - accuracy: 0.7339 - loss: 0.5401 \n",
      "Epoch 16/75\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5432 - accuracy: 0.7349\n",
      "Epoch 17/75\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5435 - accuracy: 0.7344\n",
      "Epoch 18/75\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5429 - accuracy: 0.7365\n",
      "Epoch 19/75\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5431 - accuracy: 0.7348\n",
      "Epoch 20/75\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5430 - accuracy: 0.7353\n",
      "Epoch 21/75\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5427 - accuracy: 0.7360\n",
      "Epoch 22/75\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5423 - accuracy: 0.7355\n",
      "Epoch 23/75\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5420 - accuracy: 0.7360\n",
      "Epoch 24/75\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5421 - accuracy: 0.7364\n",
      "Epoch 25/75\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5421 - accuracy: 0.7354\n",
      "Epoch 26/75\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5417 - accuracy: 0.7363\n",
      "Epoch 27/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5416 - accuracy: 0.7364\n",
      "Epoch 28/75\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5413 - accuracy: 0.7367\n",
      "Epoch 29/75\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5412 - accuracy: 0.7365\n",
      "Epoch 30/75\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5408 - accuracy: 0.7372\n",
      "Epoch 31/75\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5412 - accuracy: 0.7365\n",
      "Epoch 32/75\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5409 - accuracy: 0.7372\n",
      "Epoch 33/75\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5410 - accuracy: 0.7367\n",
      "Epoch 34/75\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5406 - accuracy: 0.7368\n",
      "Epoch 35/75\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5404 - accuracy: 0.7367\n",
      "Epoch 36/75\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5401 - accuracy: 0.7372\n",
      "Epoch 37/75\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5406 - accuracy: 0.7372\n",
      "Epoch 38/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5403 - accuracy: 0.7380\n",
      "Epoch 39/75\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5401 - accuracy: 0.7377\n",
      "Epoch 40/75\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5403 - accuracy: 0.7372\n",
      "Epoch 41/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5399 - accuracy: 0.7364\n",
      "Epoch 42/75\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5401 - accuracy: 0.7379\n",
      "Epoch 43/75\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5396 - accuracy: 0.7385\n",
      "Epoch 44/75\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5397 - accuracy: 0.7363\n",
      "Epoch 45/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5397 - accuracy: 0.7376\n",
      "Epoch 46/75\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5393 - accuracy: 0.7370\n",
      "Epoch 47/75\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5391 - accuracy: 0.7393\n",
      "Epoch 48/75\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5395 - accuracy: 0.7375\n",
      "Epoch 49/75\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5393 - accuracy: 0.7382\n",
      "Epoch 50/75\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5391 - accuracy: 0.7376\n",
      "Epoch 51/75\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5393 - accuracy: 0.7379\n",
      "Epoch 52/75\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.5391 - accuracy: 0.7371\n",
      "Epoch 53/75\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5389 - accuracy: 0.7385\n",
      "Epoch 54/75\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5390 - accuracy: 0.7383\n",
      "Epoch 55/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5388 - accuracy: 0.7389\n",
      "Epoch 56/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5391 - accuracy: 0.7369\n",
      "Epoch 57/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5385 - accuracy: 0.7386\n",
      "Epoch 58/75\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5389 - accuracy: 0.7380\n",
      "Epoch 59/75\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5387 - accuracy: 0.7371\n",
      "Epoch 60/75\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5381 - accuracy: 0.7386\n",
      "Epoch 61/75\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5385 - accuracy: 0.7386\n",
      "Epoch 62/75\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5381 - accuracy: 0.7386\n",
      "Epoch 63/75\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5384 - accuracy: 0.7385\n",
      "Epoch 64/75\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5383 - accuracy: 0.7374\n",
      "Epoch 65/75\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5384 - accuracy: 0.7386\n",
      "Epoch 66/75\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5383 - accuracy: 0.7379\n",
      "Epoch 67/75\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5381 - accuracy: 0.7391\n",
      "Epoch 68/75\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5383 - accuracy: 0.7381\n",
      "Epoch 69/75\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5382 - accuracy: 0.7383\n",
      "Epoch 70/75\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5382 - accuracy: 0.7390\n",
      "Epoch 71/75\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5385 - accuracy: 0.7374\n",
      "Epoch 72/75\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5385 - accuracy: 0.7385\n",
      "Epoch 73/75\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5383 - accuracy: 0.7384\n",
      "Epoch 74/75\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5380 - accuracy: 0.7382\n",
      "Epoch 75/75\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5379 - accuracy: 0.7378\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_5.fit(X_train_scaled,y_train,epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5537 - accuracy: 0.7259\n",
      "Loss: 0.5537094553218986, Accuracy: 0.7259474992752075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 12)                696       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 923\n",
      "Trainable params: 923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 10\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_6.add(tf.keras.layers.Dense(units=1, activation=\"tanh\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_6.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/75\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.6545 - accuracy: 0.7052s - loss: 0.6769 - accura\n",
      "Epoch 2/75\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5773 - accuracy: 0.7238\n",
      "Epoch 3/75\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5648 - accuracy: 0.7274\n",
      "Epoch 4/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5593 - accuracy: 0.7288\n",
      "Epoch 5/75\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5585 - accuracy: 0.7286\n",
      "Epoch 6/75\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5567 - accuracy: 0.7292\n",
      "Epoch 7/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5556 - accuracy: 0.7297\n",
      "Epoch 8/75\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5545 - accuracy: 0.7314\n",
      "Epoch 9/75\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5561 - accuracy: 0.7304\n",
      "Epoch 10/75\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5539 - accuracy: 0.7318\n",
      "Epoch 11/75\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5515 - accuracy: 0.7304\n",
      "Epoch 12/75\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5522 - accuracy: 0.7313\n",
      "Epoch 13/75\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.5523 - accuracy: 0.7320\n",
      "Epoch 14/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5488 - accuracy: 0.7313\n",
      "Epoch 15/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5494 - accuracy: 0.7315\n",
      "Epoch 16/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5486 - accuracy: 0.7324\n",
      "Epoch 17/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5492 - accuracy: 0.7319\n",
      "Epoch 18/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5487 - accuracy: 0.7321\n",
      "Epoch 19/75\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.5488 - accuracy: 0.7322\n",
      "Epoch 20/75\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5504 - accuracy: 0.7311\n",
      "Epoch 21/75\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5490 - accuracy: 0.7331\n",
      "Epoch 22/75\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5472 - accuracy: 0.7326\n",
      "Epoch 23/75\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5475 - accuracy: 0.7328\n",
      "Epoch 24/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5467 - accuracy: 0.7343\n",
      "Epoch 25/75\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5473 - accuracy: 0.7338\n",
      "Epoch 26/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5477 - accuracy: 0.7342\n",
      "Epoch 27/75\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.73 - 2s 94us/sample - loss: 0.5472 - accuracy: 0.7336\n",
      "Epoch 28/75\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5486 - accuracy: 0.7339\n",
      "Epoch 29/75\n",
      "25724/25724 [==============================] - 1s 37us/sample - loss: 0.5475 - accuracy: 0.7334\n",
      "Epoch 30/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5451 - accuracy: 0.7339\n",
      "Epoch 31/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5467 - accuracy: 0.7348\n",
      "Epoch 32/75\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5481 - accuracy: 0.7332\n",
      "Epoch 33/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5455 - accuracy: 0.7355\n",
      "Epoch 34/75\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5458 - accuracy: 0.7340\n",
      "Epoch 35/75\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5452 - accuracy: 0.7350\n",
      "Epoch 36/75\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5446 - accuracy: 0.7351\n",
      "Epoch 37/75\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.5449 - accuracy: 0.7352\n",
      "Epoch 38/75\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5473 - accuracy: 0.7353\n",
      "Epoch 39/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5448 - accuracy: 0.7357\n",
      "Epoch 40/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5447 - accuracy: 0.7350\n",
      "Epoch 41/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5448 - accuracy: 0.7337\n",
      "Epoch 42/75\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5448 - accuracy: 0.7343\n",
      "Epoch 43/75\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5440 - accuracy: 0.7342\n",
      "Epoch 44/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5455 - accuracy: 0.7343\n",
      "Epoch 45/75\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5440 - accuracy: 0.7358\n",
      "Epoch 46/75\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5482 - accuracy: 0.7364\n",
      "Epoch 47/75\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5479 - accuracy: 0.7357\n",
      "Epoch 48/75\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5471 - accuracy: 0.7368\n",
      "Epoch 49/75\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5477 - accuracy: 0.7349\n",
      "Epoch 50/75\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5449 - accuracy: 0.7352\n",
      "Epoch 51/75\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5438 - accuracy: 0.7355\n",
      "Epoch 52/75\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.5448 - accuracy: 0.7360\n",
      "Epoch 53/75\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5438 - accuracy: 0.7358\n",
      "Epoch 54/75\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5428 - accuracy: 0.7349\n",
      "Epoch 55/75\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5429 - accuracy: 0.7358\n",
      "Epoch 56/75\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5434 - accuracy: 0.7356\n",
      "Epoch 57/75\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5432 - accuracy: 0.7361\n",
      "Epoch 58/75\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5427 - accuracy: 0.7357\n",
      "Epoch 59/75\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5432 - accuracy: 0.7365\n",
      "Epoch 60/75\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5431 - accuracy: 0.7360\n",
      "Epoch 61/75\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5427 - accuracy: 0.7347\n",
      "Epoch 62/75\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5443 - accuracy: 0.7352\n",
      "Epoch 63/75\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5431 - accuracy: 0.7349\n",
      "Epoch 64/75\n",
      "25724/25724 [==============================] - 1s 38us/sample - loss: 0.5434 - accuracy: 0.7352\n",
      "Epoch 65/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5433 - accuracy: 0.7356\n",
      "Epoch 66/75\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5462 - accuracy: 0.7357\n",
      "Epoch 67/75\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5430 - accuracy: 0.7342\n",
      "Epoch 68/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5434 - accuracy: 0.7366\n",
      "Epoch 69/75\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5446 - accuracy: 0.7347\n",
      "Epoch 70/75\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.5434 - accuracy: 0.7360\n",
      "Epoch 71/75\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5447 - accuracy: 0.7365\n",
      "Epoch 72/75\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5443 - accuracy: 0.7370\n",
      "Epoch 73/75\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5436 - accuracy: 0.7357\n",
      "Epoch 74/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5429 - accuracy: 0.7363\n",
      "Epoch 75/75\n",
      "25724/25724 [==============================] - 1s 39us/sample - loss: 0.5451 - accuracy: 0.7358\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_6.fit(X_train_scaled,y_train,epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5545 - accuracy: 0.7261\n",
      "Loss: 0.5545304873733409, Accuracy: 0.726064145565033\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 24)                1392      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,805\n",
      "Trainable params: 1,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_7 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_7.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_7.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_7.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_7.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_7.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5824 - accuracy: 0.7126\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5563 - accuracy: 0.7284\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5512 - accuracy: 0.7315\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5486 - accuracy: 0.7327\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5474 - accuracy: 0.7327\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5457 - accuracy: 0.7331\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5450 - accuracy: 0.7348\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5444 - accuracy: 0.7345\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5433 - accuracy: 0.7349\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5429 - accuracy: 0.7351\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5425 - accuracy: 0.7362\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5423 - accuracy: 0.7355\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5422 - accuracy: 0.7359\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5414 - accuracy: 0.7365\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5414 - accuracy: 0.7364\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5410 - accuracy: 0.7369\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5413 - accuracy: 0.7369\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.5405 - accuracy: 0.7365\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5403 - accuracy: 0.7377\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5404 - accuracy: 0.7375\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5402 - accuracy: 0.7379\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5397 - accuracy: 0.7385\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5400 - accuracy: 0.7369\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5394 - accuracy: 0.7372\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5392 - accuracy: 0.7378\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5393 - accuracy: 0.7370\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5390 - accuracy: 0.7372\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5384 - accuracy: 0.7374\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5385 - accuracy: 0.7373\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5390 - accuracy: 0.7380\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5380 - accuracy: 0.7382\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5381 - accuracy: 0.7378\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5380 - accuracy: 0.7379\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5380 - accuracy: 0.7379\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5378 - accuracy: 0.7379\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5378 - accuracy: 0.7383\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5379 - accuracy: 0.7384\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.5375 - accuracy: 0.7380\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5377 - accuracy: 0.7385\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5377 - accuracy: 0.7382\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 56us/sample - loss: 0.5373 - accuracy: 0.7383\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 1s 53us/sample - loss: 0.5369 - accuracy: 0.7386\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5373 - accuracy: 0.7384\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5372 - accuracy: 0.7382\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5373 - accuracy: 0.7386\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5369 - accuracy: 0.7379\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 55us/sample - loss: 0.5370 - accuracy: 0.7393\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5367 - accuracy: 0.7388\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5369 - accuracy: 0.7390\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_7.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5506 - accuracy: 0.7272\n",
      "Loss: 0.5505541829882141, Accuracy: 0.7272303104400635\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_7.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 24)                1392      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,705\n",
      "Trainable params: 1,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "# hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_8 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_8.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_8.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# # Third hidden layer\n",
    "# nn_8.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_8.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_8.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5939 - accuracy: 0.7087\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5580 - accuracy: 0.7293\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5519 - accuracy: 0.7297\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5499 - accuracy: 0.7308\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5486 - accuracy: 0.7313\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5474 - accuracy: 0.7332\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5468 - accuracy: 0.7326\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5457 - accuracy: 0.7327\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5453 - accuracy: 0.7339\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5446 - accuracy: 0.7349\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5438 - accuracy: 0.7351\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 1s 54us/sample - loss: 0.5438 - accuracy: 0.7355\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5432 - accuracy: 0.7350\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5429 - accuracy: 0.7352\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5421 - accuracy: 0.7353\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.5417 - accuracy: 0.7362\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5422 - accuracy: 0.7360\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5415 - accuracy: 0.7370\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5414 - accuracy: 0.7361\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5408 - accuracy: 0.7356\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5407 - accuracy: 0.7367\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5407 - accuracy: 0.7350\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5407 - accuracy: 0.7367\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5403 - accuracy: 0.7353\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5402 - accuracy: 0.7371\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5398 - accuracy: 0.7373\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5397 - accuracy: 0.7375\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5401 - accuracy: 0.7360\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5398 - accuracy: 0.7359\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 1s 58us/sample - loss: 0.5392 - accuracy: 0.7374\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5395 - accuracy: 0.7368\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5391 - accuracy: 0.7377\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5391 - accuracy: 0.7387\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5388 - accuracy: 0.7374\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5388 - accuracy: 0.7382\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5389 - accuracy: 0.7377\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5386 - accuracy: 0.7371\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5387 - accuracy: 0.7391\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5383 - accuracy: 0.7372\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5384 - accuracy: 0.7375\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.5381 - accuracy: 0.7388\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5382 - accuracy: 0.7377\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5379 - accuracy: 0.7385\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5379 - accuracy: 0.7387\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5381 - accuracy: 0.7387\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5378 - accuracy: 0.7386\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5378 - accuracy: 0.7399\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5376 - accuracy: 0.7388\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5374 - accuracy: 0.7387\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5372 - accuracy: 0.7377\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_8.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5538 - accuracy: 0.7250\n",
      "Loss: 0.5537756930217799, Accuracy: 0.7250145673751831\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_8.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Model design with binning of \"CLASSIFICATION\" and \"NAME\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "charity_df = pd.read_csv('Resources/charity_data.csv')\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_3 = charity_df.copy()\n",
    "charity_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME',\n",
       " 'APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat_3 = charity_3.dtypes[charity_3.dtypes == \"object\"].index.tolist()\n",
    "charity_cat_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_3[charity_cat_3].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C2300       32\n",
       "C7200       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C6000       15\n",
       "C1800       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1278       10\n",
       "C1238       10\n",
       "C1235        9\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the CLASSIFICATION value counts\n",
    "classification_counts_3 = charity_3.CLASSIFICATION.value_counts()\n",
    "classification_counts_3.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace for bucketing\n",
    "replace_classifications_3 = list(classification_counts_3[classification_counts_3 < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in DataFrame\n",
    "for classification in replace_classifications_3:\n",
    "    charity_3.CLASSIFICATION = charity_3.CLASSIFICATION.replace(classification,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure bucketing was successful\n",
    "charity_3.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARENT BOOSTER USA INC                                                1260\n",
       "TOPS CLUB INC                                                          765\n",
       "UNITED STATES BOWLING CONGRESS INC                                     700\n",
       "WASHINGTON STATE UNIVERSITY                                            492\n",
       "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                        408\n",
       "PTA TEXAS CONGRESS                                                     368\n",
       "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC                          331\n",
       "ALPHA PHI SIGMA                                                        313\n",
       "TOASTMASTERS INTERNATIONAL                                             293\n",
       "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS                      287\n",
       "LITTLE LEAGUE BASEBALL INC                                             277\n",
       "INTERNATIONAL ASSOCIATION OF LIONS CLUBS                               266\n",
       "MOMS CLUB                                                              210\n",
       "INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION     206\n",
       "AMERICAN ASSOCIATION OF UNIVERSITY WOMEN                               197\n",
       "FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA                   166\n",
       "KNIGHTS OF COLUMBUS                                                    158\n",
       "HABITAT FOR HUMANITY INTERNATIONAL INC                                 154\n",
       "TENNESSEE ORDER OF THE EASTERN STAR                                    151\n",
       "VETERANS OF FOREIGN WARS OF THE UNITED STATES AUXILIARY                144\n",
       "PTA UTAH CONGRESS                                                      140\n",
       "THE UNITED STATES PONY CLUBS INC                                       136\n",
       "CIVITAN INTERNATIONAL                                                  131\n",
       "SIGMA BETA DELTA INC                                                   127\n",
       "MONTANA 4-H FOUNDATION INC                                             107\n",
       "HONOR SOCIETY OF PHI KAPPA PHI                                         107\n",
       "WASHINGTON STATE GRANGE                                                106\n",
       "UNIVERSITY OF WYOMING                                                  105\n",
       "DEMOLAY INTERNATIONAL                                                  104\n",
       "SERTOMA INC                                                            103\n",
       "AIR FORCE ASSOCIATION                                                   99\n",
       "WORKERS UNITED                                                          97\n",
       "GAMMA THETA UPSILON                                                     92\n",
       "INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS                              91\n",
       "SOCIETY OF SAINT VINCENT DE PAUL COUNCIL OF LOS ANGELES                 87\n",
       "Name: NAME, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the NAME value counts\n",
    "name_counts_3 = charity_3.NAME.value_counts()\n",
    "name_counts_3.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace for bucketing\n",
    "replace_names_3 = list(name_counts_3[name_counts_3 < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in DataFrame\n",
    "for name in replace_names_3:\n",
    "    charity_3.NAME = charity_3.NAME.replace(name,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                                                                 25987\n",
       "PARENT BOOSTER USA INC                                                 1260\n",
       "TOPS CLUB INC                                                           765\n",
       "UNITED STATES BOWLING CONGRESS INC                                      700\n",
       "WASHINGTON STATE UNIVERSITY                                             492\n",
       "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                         408\n",
       "PTA TEXAS CONGRESS                                                      368\n",
       "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC                           331\n",
       "ALPHA PHI SIGMA                                                         313\n",
       "TOASTMASTERS INTERNATIONAL                                              293\n",
       "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS                       287\n",
       "LITTLE LEAGUE BASEBALL INC                                              277\n",
       "INTERNATIONAL ASSOCIATION OF LIONS CLUBS                                266\n",
       "MOMS CLUB                                                               210\n",
       "INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION      206\n",
       "AMERICAN ASSOCIATION OF UNIVERSITY WOMEN                                197\n",
       "FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA                    166\n",
       "KNIGHTS OF COLUMBUS                                                     158\n",
       "HABITAT FOR HUMANITY INTERNATIONAL INC                                  154\n",
       "TENNESSEE ORDER OF THE EASTERN STAR                                     151\n",
       "VETERANS OF FOREIGN WARS OF THE UNITED STATES AUXILIARY                 144\n",
       "PTA UTAH CONGRESS                                                       140\n",
       "THE UNITED STATES PONY CLUBS INC                                        136\n",
       "CIVITAN INTERNATIONAL                                                   131\n",
       "SIGMA BETA DELTA INC                                                    127\n",
       "MONTANA 4-H FOUNDATION INC                                              107\n",
       "HONOR SOCIETY OF PHI KAPPA PHI                                          107\n",
       "WASHINGTON STATE GRANGE                                                 106\n",
       "UNIVERSITY OF WYOMING                                                   105\n",
       "DEMOLAY INTERNATIONAL                                                   104\n",
       "SERTOMA INC                                                             103\n",
       "Name: NAME, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure bucketing was successful\n",
    "charity_3.NAME.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder instance\n",
    "enc3 = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   76   77   78   79  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "\n",
       "    80   81   82   83   84   85  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_3 = pd.DataFrame(enc3.fit_transform(charity_3[charity_cat_3]))\n",
    "encode_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_ALPHA PHI SIGMA</th>\n",
       "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
       "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
       "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
       "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
       "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
       "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
       "      <th>NAME_HONOR SOCIETY OF PHI KAPPA PHI</th>\n",
       "      <th>NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS</th>\n",
       "      <th>NAME_INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL &amp; TRANSPORTATION</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_ALPHA PHI SIGMA  NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
       "0                   0.0                                                0.0      \n",
       "1                   0.0                                                0.0      \n",
       "2                   0.0                                                0.0      \n",
       "3                   0.0                                                0.0      \n",
       "4                   0.0                                                0.0      \n",
       "\n",
       "   NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  NAME_CIVITAN INTERNATIONAL  \\\n",
       "0                                            0.0                         0.0   \n",
       "1                                            0.0                         0.0   \n",
       "2                                            0.0                         0.0   \n",
       "3                                            0.0                         0.0   \n",
       "4                                            0.0                         0.0   \n",
       "\n",
       "   NAME_DEMOLAY INTERNATIONAL  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
       "0                                                0.0           \n",
       "1                                                0.0           \n",
       "2                                                0.0           \n",
       "3                                                0.0           \n",
       "4                                                0.0           \n",
       "\n",
       "   NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   NAME_HONOR SOCIETY OF PHI KAPPA PHI  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   NAME_INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION  \\\n",
       "0                                                0.0                         \n",
       "1                                                0.0                         \n",
       "2                                                0.0                         \n",
       "3                                                0.0                         \n",
       "4                                                0.0                         \n",
       "\n",
       "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0  ...                0.0                     0.0                       0.0   \n",
       "1  ...                1.0                     0.0                       0.0   \n",
       "2  ...                0.0                     0.0                       0.0   \n",
       "3  ...                0.0                     1.0                       0.0   \n",
       "4  ...                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the encoded variable names to the DataFrame\n",
    "encode_3.columns = enc3.get_feature_names(charity_cat_3)\n",
    "encode_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>NAME_ALPHA PHI SIGMA</th>\n",
       "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
       "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
       "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
       "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
       "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN  STATUS  ASK_AMT  IS_SUCCESSFUL  NAME_ALPHA PHI SIGMA  \\\n",
       "0  10520599       1     5000              1                   0.0   \n",
       "1  10531628       1   108590              1                   0.0   \n",
       "2  10547893       1     5000              0                   0.0   \n",
       "3  10553066       1     6692              1                   0.0   \n",
       "4  10556103       1   142590              1                   0.0   \n",
       "\n",
       "   NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  NAME_CIVITAN INTERNATIONAL  \\\n",
       "0                                            0.0                         0.0   \n",
       "1                                            0.0                         0.0   \n",
       "2                                            0.0                         0.0   \n",
       "3                                            0.0                         0.0   \n",
       "4                                            0.0                         0.0   \n",
       "\n",
       "   NAME_DEMOLAY INTERNATIONAL  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  ...  \\\n",
       "0                                                0.0          ...   \n",
       "1                                                0.0          ...   \n",
       "2                                                0.0          ...   \n",
       "3                                                0.0          ...   \n",
       "4                                                0.0          ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "charity_enc_3 = charity_3.merge(encode_3,left_index=True, right_index=True)\n",
    "charity_enc_3 = charity_enc_3.drop(charity_cat_3,1)\n",
    "charity_enc_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our target and features arrays\n",
    "y = charity_enc_3[\"IS_SUCCESSFUL\"].values\n",
    "X = charity_enc_3.drop([\"IS_SUCCESSFUL\"],1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 24)                2160      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 2,473\n",
      "Trainable params: 2,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn_9 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_9.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_9.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_9.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_9.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5301 - accuracy: 0.7327\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.4925 - accuracy: 0.7561\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 3s 97us/sample - loss: 0.4877 - accuracy: 0.7594\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.4854 - accuracy: 0.7596\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.4834 - accuracy: 0.7596\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.4820 - accuracy: 0.7615\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.4811 - accuracy: 0.7621\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4804 - accuracy: 0.7616\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.4798 - accuracy: 0.7633\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 0.4793 - accuracy: 0.7622\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4785 - accuracy: 0.7633\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4783 - accuracy: 0.7632\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.4777 - accuracy: 0.7630\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4774 - accuracy: 0.7639\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4772 - accuracy: 0.7622\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.4768 - accuracy: 0.7636\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.4762 - accuracy: 0.7656\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.4758 - accuracy: 0.7650\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4758 - accuracy: 0.7659\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.4754 - accuracy: 0.7659\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.4746 - accuracy: 0.7657\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.4749 - accuracy: 0.7645\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4742 - accuracy: 0.7651\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.4743 - accuracy: 0.7652\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4741 - accuracy: 0.7651\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.4738 - accuracy: 0.7667\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.4734 - accuracy: 0.7657\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.4732 - accuracy: 0.7653\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4728 - accuracy: 0.7666\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4726 - accuracy: 0.7684\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.4722 - accuracy: 0.7686\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4723 - accuracy: 0.7671\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.4719 - accuracy: 0.7676\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4717 - accuracy: 0.7669\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4715 - accuracy: 0.7666\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4712 - accuracy: 0.7673\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4709 - accuracy: 0.7664\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4710 - accuracy: 0.7678\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.4708 - accuracy: 0.7683\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4702 - accuracy: 0.7680\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.4708 - accuracy: 0.7678\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.4701 - accuracy: 0.7682\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4701 - accuracy: 0.7690\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4704 - accuracy: 0.7687\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.76 - 2s 83us/sample - loss: 0.4695 - accuracy: 0.7680\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.4689 - accuracy: 0.7685\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.4692 - accuracy: 0.7674\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4690 - accuracy: 0.7681\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4690 - accuracy: 0.7700\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4686 - accuracy: 0.7683\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_9.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5000 - accuracy: 0.7538\n",
      "Loss: 0.5000275956715509, Accuracy: 0.7538192272186279\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_9.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 24)                2160      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,573\n",
      "Trainable params: 2,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_10 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_10.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_10.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_10.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_10.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_10.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5293 - accuracy: 0.7306\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4948 - accuracy: 0.7528\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 5s 177us/sample - loss: 0.4902 - accuracy: 0.7561 - loss: 0.4596 - accura - ETA: 5s - loss: 0.4588  - ETA: 7s - loss: 0.46\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.4864 - accuracy: 0.7599\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4846 - accuracy: 0.7606\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.4829 - accuracy: 0.7604\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.4821 - accuracy: 0.7612\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.4807 - accuracy: 0.7640\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4805 - accuracy: 0.7630\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.4796 - accuracy: 0.7641\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4791 - accuracy: 0.7626\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.4784 - accuracy: 0.7645\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 5s 187us/sample - loss: 0.4778 - accuracy: 0.7646 - loss: 0.4759 - accuracy: 0.76 - -\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4776 - accuracy: 0.7644\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.4766 - accuracy: 0.7652\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4762 - accuracy: 0.7647\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.4757 - accuracy: 0.7642\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.4755 - accuracy: 0.7652\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.4759 - accuracy: 0.7668\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.4747 - accuracy: 0.7670\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.4746 - accuracy: 0.7663\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4749 - accuracy: 0.7667\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.4746 - accuracy: 0.7665\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.4738 - accuracy: 0.7662\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.4739 - accuracy: 0.7661\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.4728 - accuracy: 0.7668\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.4731 - accuracy: 0.7670\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.4727 - accuracy: 0.7663\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.4726 - accuracy: 0.7673\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.4719 - accuracy: 0.7675\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.4717 - accuracy: 0.7672\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.4719 - accuracy: 0.7685\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.4712 - accuracy: 0.7688\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.4712 - accuracy: 0.7688\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.4709 - accuracy: 0.7673\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.4716 - accuracy: 0.7673\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.4709 - accuracy: 0.7675\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.4705 - accuracy: 0.7682\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.4702 - accuracy: 0.7693 - loss: 0.471\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.4701 - accuracy: 0.7687\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.4701 - accuracy: 0.7687\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4700 - accuracy: 0.7683\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.4696 - accuracy: 0.7690\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 3s 136us/sample - loss: 0.4693 - accuracy: 0.7684\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.4691 - accuracy: 0.7685\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.4685 - accuracy: 0.7685 - loss: 0.4707 - accuracy: 0.76 - ETA: 0s - loss: 0.4704 - accuracy: 0.76 - ETA: 0s - l - ETA: 0s - loss: 0.4700 \n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4688 - accuracy: 0.7701\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.4690 - accuracy: 0.7693\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.4684 - accuracy: 0.7710\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.4684 - accuracy: 0.7696\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_10.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.4978 - accuracy: 0.7511\n",
      "Loss: 0.4977589841104457, Accuracy: 0.7511370182037354\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_10.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 24)                2160      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 2,785\n",
      "Trainable params: 2,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "hidden_nodes_layer2 = 24\n",
    "# hidden_nodes_layer3 = 8\n",
    "\n",
    "nn_11 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_11.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_11.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# # Third hidden layer\n",
    "# nn_11.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_11.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_11.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5229 - accuracy: 0.7339\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.4925 - accuracy: 0.7562\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.4878 - accuracy: 0.7575\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 3s 106us/sample - loss: 0.4854 - accuracy: 0.7591\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.4842 - accuracy: 0.7593\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4823 - accuracy: 0.7613\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7633 ETA:  - 3s 125us/sample - loss: 0.4813 - accuracy: 0.7630\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.4803 - accuracy: 0.7633\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.4799 - accuracy: 0.7645\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4784 - accuracy: 0.7641\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 0.4781 - accuracy: 0.7651\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4774 - accuracy: 0.7643\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4768 - accuracy: 0.7648\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.4755 - accuracy: 0.7645\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 0.4757 - accuracy: 0.7655\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4751 - accuracy: 0.7671\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4752 - accuracy: 0.7645\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.4741 - accuracy: 0.7666\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 3s 133us/sample - loss: 0.4738 - accuracy: 0.7671\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 0.4731 - accuracy: 0.7672\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.4734 - accuracy: 0.7671\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.4725 - accuracy: 0.7666\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4724 - accuracy: 0.7674\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.4721 - accuracy: 0.7680\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.4717 - accuracy: 0.7675\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.4712 - accuracy: 0.7685\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.4710 - accuracy: 0.7690\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4706 - accuracy: 0.7675\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.4707 - accuracy: 0.7681\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.4700 - accuracy: 0.7690\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.4697 - accuracy: 0.7700\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 6s 220us/sample - loss: 0.4698 - accuracy: 0.7692 - loss: 0.4699 - ac - ETA: 1s - loss: 0.4701 - ac - ETA: 1s - loss: 0.4701 - accuracy:  -\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.4693 - accuracy: 0.7699\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.4684 - accuracy: 0.7682\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4691 - accuracy: 0.7698\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4682 - accuracy: 0.7710\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.4684 - accuracy: 0.7700\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.4681 - accuracy: 0.7701\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 4s 161us/sample - loss: 0.4673 - accuracy: 0.7714 - loss:\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.4677 - accuracy: 0.7706\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.4673 - accuracy: 0.7711\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.4666 - accuracy: 0.7701\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 5s 201us/sample - loss: 0.4670 - accuracy: 0.7714\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.4669 - accuracy: 0.7722\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.4661 - accuracy: 0.7719\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 3s 97us/sample - loss: 0.4663 - accuracy: 0.7724\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.4658 - accuracy: 0.7704 - loss: 0.4658 - accuracy - ETA: 1s - loss: 0.4664 - accu\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4659 - accuracy: 0.7719\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.4654 - accuracy: 0.7724\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.4657 - accuracy: 0.7722\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_11.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.5032 - accuracy: 0.7514\n",
      "Loss: 0.5032284814692795, Accuracy: 0.7513702511787415\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_11.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 36)                3240      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 37        \n",
      "=================================================================\n",
      "Total params: 3,277\n",
      "Trainable params: 3,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 36\n",
    "# hidden_nodes_layer2 = 12\n",
    "\n",
    "nn_12 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_12.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# # Second hidden layer\n",
    "# nn_12.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_12.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_12.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.5202 - accuracy: 0.7340\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 3s 131us/sample - loss: 0.4942 - accuracy: 0.7548\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4904 - accuracy: 0.7573\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.4887 - accuracy: 0.7581\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 3s 105us/sample - loss: 0.4862 - accuracy: 0.7605\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4863 - accuracy: 0.7598\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 5s 179us/sample - loss: 0.4845 - accuracy: 0.7602\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.4843 - accuracy: 0.7597\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.4833 - accuracy: 0.7621\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4829 - accuracy: 0.7607\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4822 - accuracy: 0.7603\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4821 - accuracy: 0.7617\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.4811 - accuracy: 0.7610\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4816 - accuracy: 0.7621\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.4811 - accuracy: 0.7621\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4801 - accuracy: 0.7635\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.4796 - accuracy: 0.7635\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4798 - accuracy: 0.7644\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4799 - accuracy: 0.7632\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4798 - accuracy: 0.7631\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.4788 - accuracy: 0.7624\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.4790 - accuracy: 0.7629\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4784 - accuracy: 0.7638\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4787 - accuracy: 0.7637\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4776 - accuracy: 0.7642\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 0.4783 - accuracy: 0.7638\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4779 - accuracy: 0.7640\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 0.4779 - accuracy: 0.7652 - loss: 0.4762 -  - ETA\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.4777 - accuracy: 0.7629 - loss: 0.4806 - accu - ETA: 0s - l\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.4777 - accuracy: 0.7649 - loss: 0.4761 - accuracy:  - ETA: 1s - loss: - ETA: 1s - los\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.4774 - accuracy: 0.7629\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4770 - accuracy: 0.7637\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4772 - accuracy: 0.7641\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.4767 - accuracy: 0.7628\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.4772 - accuracy: 0.7640\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.4769 - accuracy: 0.7644\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.4763 - accuracy: 0.7650\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.4767 - accuracy: 0.7642\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.4759 - accuracy: 0.7645\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.4762 - accuracy: 0.7642\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 3s 131us/sample - loss: 0.4755 - accuracy: 0.7655\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 4s 145us/sample - loss: 0.4757 - accuracy: 0.7651\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.4758 - accuracy: 0.7647\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.4754 - accuracy: 0.7647\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.4754 - accuracy: 0.7651\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4753 - accuracy: 0.7664\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4751 - accuracy: 0.7655\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.4752 - accuracy: 0.7645\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.4745 - accuracy: 0.7668\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.4747 - accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_12.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.4962 - accuracy: 0.7520\n",
      "Loss: 0.4962383259871958, Accuracy: 0.7519533634185791\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_12.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 24)                2160      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 2,185\n",
      "Trainable params: 2,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 24\n",
    "# hidden_nodes_layer2 = 12\n",
    "\n",
    "nn_13 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_13.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# # Second hidden layer\n",
    "# nn_12.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_13.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_13.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5302 - accuracy: 0.7265\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.4965 - accuracy: 0.7496\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.4915 - accuracy: 0.7537\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4894 - accuracy: 0.7550\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4871 - accuracy: 0.7567\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.4864 - accuracy: 0.7577\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4853 - accuracy: 0.7595\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 5s 177us/sample - loss: 0.4844 - accuracy: 0.7598 - - - ETA: 1s - loss: 0.4857 - accuracy:  - ETA: 1s - l\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4840 - accuracy: 0.7598\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 3s 104us/sample - loss: 0.4834 - accuracy: 0.7594\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.4829 - accuracy: 0.7614 - loss: 0.4827 - accuracy - ETA: 1s - loss: 0.4824 - accuracy:  - ETA: 1s - loss:\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.4825 - accuracy: 0.7600\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.4821 - accuracy: 0.7614\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.4810 - accuracy: 0.7621\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4811 - accuracy: 0.7612\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.4807 - accuracy: 0.7628\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4801 - accuracy: 0.7618\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4799 - accuracy: 0.7601\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.4797 - accuracy: 0.7630\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 3s 113us/sample - loss: 0.4795 - accuracy: 0.7614\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4789 - accuracy: 0.7630\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4789 - accuracy: 0.7636\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4787 - accuracy: 0.7629\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.4785 - accuracy: 0.7631\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4779 - accuracy: 0.7633\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.4781 - accuracy: 0.7624\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4776 - accuracy: 0.7629\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.4774 - accuracy: 0.7631 - los\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.4772 - accuracy: 0.7637\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.4775 - accuracy: 0.7643\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4773 - accuracy: 0.7644\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 3s 98us/sample - loss: 0.4771 - accuracy: 0.7635\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.4767 - accuracy: 0.7645\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4767 - accuracy: 0.7642\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4765 - accuracy: 0.7636\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 3s 108us/sample - loss: 0.4763 - accuracy: 0.7639\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.4762 - accuracy: 0.7650\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.4761 - accuracy: 0.7645\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.4761 - accuracy: 0.7641\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4756 - accuracy: 0.7635\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.4754 - accuracy: 0.7639\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.4759 - accuracy: 0.7644\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 3s 107us/sample - loss: 0.4752 - accuracy: 0.7653\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4755 - accuracy: 0.7647\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.4756 - accuracy: 0.7652\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.4752 - accuracy: 0.7643\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4749 - accuracy: 0.7655\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.4748 - accuracy: 0.7638\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.4750 - accuracy: 0.7641\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4746 - accuracy: 0.7648\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_13.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/8575 - 0s - loss: 0.4971 - accuracy: 0.7482\n",
      "Loss: 0.497126927358416, Accuracy: 0.7482215762138367\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_13.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
